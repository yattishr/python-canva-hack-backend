import json
import asyncio
import random
import time
import io
import os
from dotenv import load_dotenv
import pandas as pd
import google.generativeai as genai
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from pydantic import BaseModel
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Setting up the API key
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY is not set in the environment variables")

# Define the Output class


# Configure Gemini
genai.configure(api_key=GOOGLE_API_KEY)

app = FastAPI()

# Semaphore to limit the number of concurrent requests
MAX_CONCURRENT_REQUESTS = 5  # Adjust based on your rate limits
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

def read_csv_data(file: UploadFile, sample_size=1000):
    try:
        contents = file.file.read()
        buffer = io.StringIO(contents.decode('utf-8'))
        df = pd.read_csv(buffer)
        return df.sample(min(sample_size, len(df)))
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Error reading CSV file: {str(e)}")

def dataframe_to_text(df: pd.DataFrame):
    return df.to_csv(index=False)

def generate_prompt_and_model(data: str, description: str, model_name: str = "gemini-1.5-pro"):
    system_prompt = """You are an expert data analyst who fully understands how to present data in story form
    that is easier for users to understand their data. Your role is to create a compelling story based on
    the data that is provided to highlight key aspects and components from the data.
    In addition, you will highlight any identifiable trends you recognize from the data and present it
    in a relatable story that the user can relate to.

    Your task is to analyze the data and provide an aggregated view of the data in a compelling story form.
    Structure your response in the following JSON format:
    {
        "title": "A catchy title for your analysis",
        "summary": "A brief summary of the key findings",
        "sections": [
            {
                "heading": "Section heading",
                "content": "Section content"
            },
            ...
        ],
        "conclusion": "A concluding paragraph"
    }"""

    generation_config = {
        "temperature": 1,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
    }

    model = genai.GenerativeModel(model_name=model_name, generation_config=generation_config)
    prompt = f"Analyze the following CSV data:\n```\nDescription of the data: {description}\n```\n{data}\n```\n{system_prompt}"

    return model, prompt

async def send_data_to_gemini(data: str, description: str, max_retries=3):
    model, prompt = generate_prompt_and_model(data, description)
    initial_delay = 2  # Initial delay before first attempt
    for attempt in range(max_retries):
        try:
            logger.info(f"Sending the prompt to the model (attempt {attempt + 1})...")
            chat = model.start_chat(history=[])

            # Try with streaming first
            try:
                response = chat.send_message(prompt, stream=True)
                full_response = ""
                for chunk in response:
                    full_response += chunk.text
                    print(chunk.text, end="", flush=True)
            except Exception as stream_error:
                logger.warning(f"Streaming failed: {stream_error}. Retrying without streaming...")
                # If streaming fails, try without streaming
                response = chat.send_message(prompt, stream=False)
                full_response = response.text
                print(full_response)

            logger.info("Response completed.")
            return json.loads(full_response)
        except genai.types.generation_types.BlockedPromptException as e:
            logger.error(f"Blocked prompt: {e}")
            raise HTTPException(status_code=400, detail="The prompt was blocked by the API")
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            raise HTTPException(status_code=500, detail="Failed to parse Gemini response as JSON")
        except Exception as e:
            logger.error(f"An error occurred: {e}")
            if attempt < max_retries - 1:
                wait_time = initial_delay * (2 ** attempt) + random.uniform(0, 1)
                logger.info(f"Retrying in {wait_time:.2f} seconds...")
                time.sleep(wait_time)
            else:
                logger.error("Max retries reached. Exiting.")
                raise HTTPException(status_code=500, detail=f"Error in Gemini API: {str(e)}")

@app.post("/analyze")
async def analyze_csv(file: UploadFile = File(...), description: str = Form(...)):
    if not file.filename.endswith('.csv'):
        raise HTTPException(status_code=400, detail="Only CSV files are allowed")

    async with semaphore:
        try:
            df = read_csv_data(file, sample_size=1000)  # Adjust sample size as needed
            data = dataframe_to_text(df)
            response = await send_data_to_gemini(data, description)
            return response
        except genai.types.generation_types.BlockedPromptException as e:
            logger.error(f"Blocked prompt: {e}")
            raise HTTPException(status_code=400, detail="The prompt was blocked by the API")
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            raise HTTPException(status_code=500, detail="Failed to parse Gemini response as JSON")
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            if "429" in str(e):
                raise HTTPException(status_code=429, detail="API rate limit exceeded. Please try again later.")
            raise HTTPException(status_code=500, detail=f"Error in Gemini API: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)